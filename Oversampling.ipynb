{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from sksurv.ensemble import RandomSurvivalForest, GradientBoostingSurvivalAnalysis\n",
    "from lifelines import CoxPHFitter, AalenAdditiveFitter, WeibullAFTFitter\n",
    "\n",
    "import smote_variants as sv\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4577ec584243a1b686973bd3c77577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=298), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "for file in tqdm_notebook(os.listdir('examples/output')):\n",
    "    features.append(pd.read_csv('examples/output/{}'.format(file), index_col=0))\n",
    "features = pd.concat(features)\n",
    "\n",
    "clin_features = ['id', 'channel', 'RecID', 'Gestation', 'Rectime', 'Age', 'Parity', \n",
    "                 'Abortions', 'Weight', 'Hypertension', 'Diabetes', 'Placental_position', \n",
    "                 'Bleeding_first_trimester', 'Bleeding_second_trimester', 'Funneling', 'Smoker']\n",
    "features['Gestation'] = features['Gestation'].astype(float)\n",
    "features['Rectime'] = features['Rectime'].astype(float)\n",
    "features['TimeToBirth'] = features['Gestation'] - features['Rectime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27091be47a924373b9adff2b034ca268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=298), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(894, 2125) (298, 6357)\n"
     ]
    }
   ],
   "source": [
    "# Create a feature matrix & multiple target vectors (preterm <-> term, ttb < 7 <-> ttb >= 7, ...)\n",
    "features[['Gestation', 'Rectime', 'Age', 'Parity', 'Abortions', 'Weight']] = features[['Gestation', 'Rectime', 'Age', 'Parity', 'Abortions', 'Weight']].replace(to_replace='None', value=np.NaN)\n",
    "\n",
    "ids = set(features['id'])\n",
    "channels = set(features['channel'])\n",
    "joined_features = []\n",
    "for _id in tqdm_notebook(ids):\n",
    "    features_id = []\n",
    "    features_filtered = features[features['id'] == _id]\n",
    "    for channel in channels:\n",
    "        channel_features = features_filtered[features_filtered['channel'] == channel]\n",
    "        col_map = {}\n",
    "        for col in channel_features:\n",
    "            if col not in clin_features:\n",
    "                col_map[col] = '{}_ch{}'.format(col, channel)\n",
    "        channel_features = channel_features.rename(columns=col_map)\n",
    "        features_id.append(channel_features)\n",
    "    features_id = pd.concat(features_id, axis=1)\n",
    "    joined_features.append(features_id)\n",
    "joined_features = pd.concat(joined_features)\n",
    "joined_features = joined_features.loc[:,~joined_features.columns.duplicated()]\n",
    "\n",
    "joined_features = pd.get_dummies(joined_features, columns=['Hypertension', 'Diabetes', 'Placental_position', 'Bleeding_first_trimester', 'Bleeding_second_trimester', 'Funneling', 'Smoker'])\n",
    "for col in ['Gestation', 'Rectime', 'Age', 'Parity', 'Abortions', 'Weight']:\n",
    "    joined_features[col] = joined_features[col].fillna(joined_features[col].median())\n",
    "    \n",
    "for col in joined_features.columns[joined_features.isnull().sum() > 0]:\n",
    "    joined_features[col] = joined_features[col].fillna(joined_features[col].mean())\n",
    "    \n",
    "\n",
    "term_preterm = joined_features['Gestation'] <= 37\n",
    "ttb_10w = joined_features['TimeToBirth_ch3'] <= 10\n",
    "ttb = joined_features['TimeToBirth_ch3']\n",
    "feature_matrix = joined_features.drop(['TimeToBirth_ch3', 'TimeToBirth_ch2', 'TimeToBirth_ch1', 'Gestation', \n",
    "                                       'RecID', 'channel', 'id'], axis=1)\n",
    "\n",
    "print(features.shape, joined_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 2773 features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(298, 3577)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Util classes & functions for feature selection\n",
    "\n",
    "def get_corr_features(X):\n",
    "    \"\"\"Get all coordinates in the X-matrix with correlation value equals 1\n",
    "    (columns with equal values), excluding elements on the diagonal.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    - train_df: pd.DataFrame\n",
    "        the feature matrix where correlated features need to be removed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - correlated_feature_pairs: list of tuples\n",
    "        coordinates (row, col) where correlated features can be found\n",
    "    \"\"\"\n",
    "    row_idx, col_idx = np.where(np.abs(X.corr()) > 0.95)\n",
    "    self_corr = set([(i, i) for i in range(X.shape[1])])\n",
    "    correlated_feature_pairs = set(list(zip(row_idx, col_idx))) - self_corr\n",
    "    return correlated_feature_pairs\n",
    "\n",
    "\n",
    "def get_uncorr_features(data):\n",
    "    \"\"\"Remove clusters of these correlated features, until only one feature \n",
    "    per cluster remains.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    - data: pd.DataFrame\n",
    "        the feature matrix where correlated features need to be removed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - data_uncorr_cols: list of string\n",
    "        the column names that are completely uncorrelated to eachother\n",
    "    \"\"\"\n",
    "    X_train_corr = data.copy()\n",
    "    correlated_features = get_corr_features(X_train_corr)\n",
    "\n",
    "    corr_cols = set()\n",
    "    for row_idx, col_idx in correlated_features:\n",
    "        corr_cols.add(row_idx)\n",
    "        corr_cols.add(col_idx)\n",
    "\n",
    "    uncorr_cols = list(set(X_train_corr.columns) - set(X_train_corr.columns[list(corr_cols)]))\n",
    "   \n",
    "    col_mask = [False]*X_train_corr.shape[1]\n",
    "    for col in corr_cols:\n",
    "        col_mask[col] = True\n",
    "    X_train_corr = X_train_corr.loc[:, col_mask]\n",
    "  \n",
    "    correlated_features = get_corr_features(X_train_corr)\n",
    "    to_remove = set()\n",
    "    for corr_row, corr_col in correlated_features:\n",
    "        if corr_row in to_remove or corr_col in to_remove:\n",
    "            continue\n",
    "\n",
    "        for corr_row2, corr_col2 in correlated_features:\n",
    "            if corr_row == corr_row2:\n",
    "                to_remove.add(corr_col2)\n",
    "            elif corr_row == corr_col2:\n",
    "                to_remove.add(corr_row2)\n",
    "\n",
    "    col_mask = [True]*X_train_corr.shape[1]\n",
    "    for ix in to_remove:\n",
    "        col_mask[ix] = False\n",
    "\n",
    "    X_train_corr = X_train_corr.loc[:, col_mask]\n",
    "\n",
    "    data_uncorr_cols = list(set(list(X_train_corr.columns) + uncorr_cols))\n",
    "\n",
    "    return data_uncorr_cols\n",
    "\n",
    "def remove_features(data):\n",
    "    \"\"\"Remove all correlated features and columns with only a single value.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    - data: pd.DataFrame\n",
    "        the feature matrix where correlated features need to be removed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - useless_cols: list of string\n",
    "        list of column names that have no predictive value\n",
    "    \"\"\"\n",
    "    single_cols = list(data.columns[data.nunique() == 1])\n",
    "\n",
    "    uncorr_cols = get_uncorr_features(data)\n",
    "    corr_cols = list(set(data.columns) - set(uncorr_cols))\n",
    "\n",
    "    useless_cols = list(set(single_cols + corr_cols))\n",
    "\n",
    "    print('Removing {} features'.format(len(useless_cols)))\n",
    "\n",
    "    return useless_cols\n",
    "\n",
    "# print(sum(feature_matrix.std(axis=0) < 0.1))\n",
    "# feature_matrix = feature_matrix.loc[:, feature_matrix.std(axis=0) >= 0.1]\n",
    "useless_features = remove_features(feature_matrix)\n",
    "\n",
    "feature_matrix = feature_matrix.drop(useless_features, axis=1)\n",
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util classes & functions for feature selection\n",
    "class PipelineRFE(Pipeline):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        super(PipelineRFE, self).fit(X, y, **fit_params)\n",
    "        print(self)\n",
    "#         self.feature_importances_ = self.steps[0][1].best_estimator_.steps[-1][1].classifier.coef_\n",
    "        self.feature_importances = self.steps[1][1].classifier.coef_\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_matrix.reset_index(drop=True)\n",
    "y = feature_matrix['Rectime'] + ttb >= 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001, 'penalty': 'l2', 'proportion': 1.0, 'n_neighbors': 7} 0.6648378191856452\n",
      "AUC = 0.6033653846153847 || Confusion Matrix =\n",
      "[[ 7  1]\n",
      " [31 21]]\n",
      "{'C': 0.001, 'penalty': 'l2', 'proportion': 0.5, 'n_neighbors': 3} 0.6428226363008972\n",
      "AUC = 0.6754807692307693 || Confusion Matrix =\n",
      "[[ 5  3]\n",
      " [17 35]]\n",
      "{'C': 0.001, 'penalty': 'l2', 'proportion': 1.5, 'n_neighbors': 3} 0.6842443064182194\n",
      "AUC = 0.4543269230769231 || Confusion Matrix =\n",
      "[[ 4  4]\n",
      " [30 22]]\n",
      "{'C': 0.001, 'penalty': 'l2', 'proportion': 1.0, 'n_neighbors': 5} 0.5263943785682916\n",
      "AUC = 0.8214285714285714 || Confusion Matrix =\n",
      "[[ 6  1]\n",
      " [18 34]]\n",
      "{'C': 10, 'penalty': 'l1', 'proportion': 1.0, 'n_neighbors': 7} 0.59648033126294\n",
      "AUC = 0.32692307692307687 || Confusion Matrix =\n",
      "[[ 0  7]\n",
      " [ 6 46]]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def tune_hyper_parameters(X, y, param_grid):\n",
    "    best_params, best_features, best_score = None, None, 0\n",
    "    combinations = list(itertools.product(*list(param_grid.values())))\n",
    "    for combination in combinations:\n",
    "        param_combination = dict(zip(param_grid.keys(), combination))\n",
    "        skf = StratifiedKFold(n_splits=3, random_state=42)\n",
    "        scores = []\n",
    "        for fold_ix, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "            X_train = X[train_idx, :]\n",
    "            X_test = X[test_idx, :]\n",
    "            y_train = y.iloc[train_idx]\n",
    "            y_test = y.iloc[test_idx]\n",
    "\n",
    "            clf = sv.OversamplingClassifier(\n",
    "                sv.SMOTE(proportion=param_combination['proportion'],\n",
    "                         n_neighbors=param_combination['n_neighbors']),\n",
    "                LogisticRegression(penalty=param_combination['penalty'],\n",
    "                                   C=param_combination['C'])\n",
    "            )\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            prob_preds = clf.predict_proba(X_test)[:, 1]\n",
    "            scores.append(roc_auc_score(y_test, prob_preds))\n",
    "        \n",
    "        agg_score = np.mean(scores)\n",
    "        if agg_score > best_score:\n",
    "            best_score = agg_score\n",
    "            best_params = param_combination\n",
    "            \n",
    "    print(best_params, best_score)\n",
    "    return best_params\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger('smote_variants')\n",
    "logger.disabled = True\n",
    "\n",
    "param_grid = {\n",
    "    'C': [10**i for i in range(-3, 4)],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'proportion': [0.5, 1.0, 1.5],\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "for fold_ix, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "    X_train = X.iloc[train_idx, :]\n",
    "    X_test = X.iloc[test_idx, :]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    y_test = y.iloc[test_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    params = tune_hyper_parameters(X_train, y_train, param_grid)\n",
    "    clf = sv.OversamplingClassifier(\n",
    "        sv.SMOTE(proportion=params['proportion'],\n",
    "                 n_neighbors=params['n_neighbors']),\n",
    "        LogisticRegression(penalty=params['penalty'],\n",
    "                           C=params['C'])\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    prob_preds = clf.predict_proba(X_test)[:, 1]\n",
    "    preds = clf.predict(X_test)\n",
    "\n",
    "    print('AUC = {} || Confusion Matrix ='.format(roc_auc_score(y_test, prob_preds)))\n",
    "    print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-1a0775922923>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-1a0775922923>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ```\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SPY\n",
    "{'C': 0.01, 'penalty': 'l2', 'threshold': 0.75, 'n_neighbors': 3}\n",
    "AUC = 0.44711538461538464 || Confusion Matrix =\n",
    "[[ 5  3]\n",
    " [30 22]]\n",
    " \n",
    "{'C': 0.001, 'penalty': 'l2', 'threshold': 0.75, 'n_neighbors': 3}\n",
    "AUC = 0.65625 || Confusion Matrix =\n",
    "[[ 5  3]\n",
    " [17 35]]\n",
    " \n",
    "{'C': 1, 'penalty': 'l1', 'threshold': 0.3, 'n_neighbors': 7}\n",
    "AUC = 0.2764423076923077 || Confusion Matrix =\n",
    "[[ 1  7]\n",
    " [ 4 48]]\n",
    " \n",
    "{'C': 0.1, 'penalty': 'l1', 'threshold': 0.75, 'n_neighbors': 7}\n",
    "AUC = 0.7197802197802198 || Confusion Matrix =\n",
    "[[ 1  6]\n",
    " [ 2 50]]\n",
    " \n",
    "{'C': 1, 'penalty': 'l1', 'threshold': 0.5, 'n_neighbors': 3}\n",
    "AUC = 0.38736263736263743 || Confusion Matrix =\n",
    "[[ 0  7]\n",
    " [ 6 46]]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SMOTE\n",
    "{'C': 0.001, 'penalty': 'l2', 'proportion': 1.0, 'n_neighbors': 3}\n",
    "AUC = 0.6201923076923077 || Confusion Matrix =\n",
    "[[ 7  1]\n",
    " [31 21]]\n",
    "{'C': 0.001, 'penalty': 'l2', 'proportion': 0.5, 'n_neighbors': 3}\n",
    "AUC = 0.65625 || Confusion Matrix =\n",
    "[[ 4  4]\n",
    " [18 34]]\n",
    "{'C': 0.001, 'penalty': 'l2', 'proportion': 1.5, 'n_neighbors': 5}\n",
    "AUC = 0.4567307692307692 || Confusion Matrix =\n",
    "[[ 4  4]\n",
    " [29 23]]\n",
    "{'C': 0.001, 'penalty': 'l2', 'proportion': 1.5, 'n_neighbors': 5}\n",
    "AUC = 0.8186813186813188 || Confusion Matrix =\n",
    "[[ 6  1]\n",
    " [18 34]]\n",
    "{'C': 0.1, 'penalty': 'l1', 'proportion': 1.0, 'n_neighbors': 3}\n",
    "AUC = 0.39010989010989017 || Confusion Matrix =\n",
    "[[ 0  7]\n",
    " [ 7 45]]\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
